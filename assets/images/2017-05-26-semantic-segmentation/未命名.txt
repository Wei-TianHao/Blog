看图说话是机器认知世界的重要部分，是实现强人工智能的必经之路。科幻电影中最基本的假设实际上却存在着非常大的困难。近年来image caption获得了突破性的进展，本文旨在介绍image caption这些年的发展历程、遇到的困难与解决的方案，并对当前的研究方向做一些展望。

image caption的想法是建立在翻译系统的表现突飞猛进的前提上。Google翻译使用RNN训练出来的模型在翻译领域取得了巨大的成就，远超之前机器翻译的表现，使用者体验后纷纷惊叹。RNN的工作模型是将一个序列输入神经网络，并输出一个预测序列。正是这种工作模式启发了工作人员们训练其进行机器翻译，在机器翻译中，这两个序列正是原句和翻译后的句子。而后人受到启发，如果我们把输入序列换成一张图片的特征，输出序列仍是一个语句，对其进行训练，是否能得到对于图片的描述呢？在这种想法的引导下，研究人员在image caption领域取得了巨大的突破，虽然还远远达不到能够实用的地步，但远超之前各种方法的表现。RNN并不具备图像识别的能力，所以RNN的输入端并不是原始图片，而是经过CNN处理后的全连接层层。CNN的最后一层是对图片进行分类，我们把这层去掉以后最后一层是这张图片的描述向量，这个向量描述了图片的各项特征。我们把这个作为一个序列输入RNN，对其进行训练，便可得到一个image caption的神经网络。但这个网络仍有许多缺陷，表现并不令人满意。为了改进这个网络，有两个主要途径，一个是提高前端图片处理网络的能力，提取出更有利于RNN训练的特征向量；另一个是改进后端生成序列网络的能力，能够根据前面的特征给出更合理的描述语句。
接下来我们先讲解第一部分的后续进展，提高图片处理网络的能力的一个很自然的想法是不仅要识别出图像中的各项特征，而最好能把图像中的各个物体标注出来，
[1]这篇论文开创了利用深度卷积神经网络进行图像识别的方法。



[1] ImageNet Classification with Deep Convolutional Neural Networks
